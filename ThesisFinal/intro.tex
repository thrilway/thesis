%        File: intro.tex
%     Created: Thu Jun 22 04:00 PM 2017 E
% Last Change: Thu Jun 22 04:00 PM 2017 E
%
% arara: pdflatex: {options: "-draftmode"}
% arara: biber
% arara: pdflatex: {options: "-draftmode"}
% arara: pdflatex: {options: "-file-line-error-style"}
\documentclass[MilwayThesis]{subfiles}

\begin{document}
This thesis asks a seemingly simple question: Why do some but not all languages allow their users to generate adjectival resultatives?
I write ``\textit{seemingly} simple'' for reasons that are likely obvious to anyone reading this, but will clarify the reasons as a way of introducing the actual content of the thesis that follows.
There are, as far as I can tell, two complications inherent in questions of the form \textit{Why P?}: one linguistic, one metaphysical.
The linguistic complication is that \textit{Why P?} presupposes that \textit{P}.
So, in order to answer, or even be justified in asking, the question at hand, we must first demonstrate that there is a class of expressions that can be called adjectival resultatives, and that they are not found in every language.
The metaphysical complication is due to the fact that a given \textit{Why} question has an indefinite number of true responses, yet the appropriate response depends on the level of explanation that is sought.
So, In order to answer the stated question, we must clarify the level of explanation we are seeking.

Beginning with the presupposition: is it the case that some but not all natural language grammars generate adjectival resultatives?
The first thing we need to answer that question is a working definition of adjectival resultatives, which I give in \cref{def:AdjRes} and which, in turn, depends on the definition of \textit{secondary predicate} in \cref{def:SecPred}.
\begin{defn}[Adjectival Resultative]\label{def:AdjRes}
	An \textit{adjectival resultative} is a secondary predication structure, whose secondary predicate is an adjective (phrase) and is interpreted as describing the a state directly caused by the event described by the primary predicate.
\end{defn}
\begin{defn}[Secondary Predication]\label{def:SecPred}
	A \textit{secondary predication} structure is a monoclausal structure containing constituent consisting of a verb (phrase) (V) an argument (DP) and another element (SP) such that\\
	SP is interpreted as a predicate,\\
	and DP is an argument of both V and SP.
\end{defn}

A canonical example of an adjectival resultative is give in (AR).
\AREx

This is a secondary predication structure in the sense that it contains a constituent \textit{hammer the metal flat} which contains a verbal and an adjectival predicate (\textit{hammer} and \textit{flat}, respectively) and a DP \textit{the metal} which is an argument of both predicates.
Furthermore, it is an adjectival resultative because its secondary predicate is the adjective \textit{flat}, which describes a state caused by the hammering event.
Resultatives contrast minimally with depictives, secondary predication structures whose secondary predicate discribes a state not caused by the primary predicate.
The sentence in \cref{ex:DepictiveCanon}, is a canonical example of a depictive.
\ex.\label{ex:DepictiveCanon} Heather ate the fish raw.

This is an example of secondary predication, with \textit{ate} being the verb, \textit{raw} being the secondary predicate, and the argument \textit{the fish} being shared between the two.
It is not a resultative because, in the situation it describes, the rawness state is in no way caused by the eating event.
So, part of the presupposition is true: Resultatives exist in a least one language.
\textcite{snyder1995language,snyder2001nature}, however, demonstrates that adjectival resultatives exist in a number of other languages, including ASL, Dutch, German, Khmer, Japanese, Korean, Hungarian, Mandarin, and Thai.
\ex. <+Resultatives+>

Furthermore, Snyder demonstrates that a number of languages seem to be incapable of generating adjectival resultatives, expressing resultatives periphrastically instead.
\ex. <StarResultatives+>

Our presupposition, then, seems to hold; some, but not all languages exhibit adjectival resultatives.

Our second issue---that of deciding what we mean by \textit{why}---I believe is a far more interesting one, as answering it requires us to be explicit about the broader goals of our inquiry.
If our interest is historical linguistics or language variation and change, then we might be interested in the migration patterns and language contact situations, and how they do or do not correlate with a language's ability to generate resultatives, or with the social factors linked to resultatives.
This thesis, however, is a work of largely theoretical generative syntax, so our \textit{why} question is actually two questions: What essential property (or properties) do grammars that generate resultatives have that grammars that do not generate resultatives lack? And how is that property (or set of properties) acquirable by children from the primary linguistic data?
Note that I have framed the acquisition question as dependent on the grammatical question---likely a reflection of my training as a syntactician---but I don't believe that one question is \textit{logically} prior to the other.
\textcite{snyder1995language,snyder2001nature}, for instance, takes the grammatical question to be dependent on the acquisition question.
I believe the questions are interdependent, meaning that the correct answer to one should at least be consistent with the correct answer to the other.
The simplest situation, however, would be that the correct answer to each question entails the correct answer to the other; in other words, that a single statement would provide an answer to both questions.

For reasons that have little to do with the content of linguistic theory or its empirical base, and a great deal to do with the social, cultural, and political atmosphere of modern scientific research, the two questions that I pose above are not commonly treated as interdependent.
Syntacticians focus on the grammatical question, and consider the acquisition question to be secondary at best, while acquisitionists consider the reverse to be the case.
This leads to syntactic proposals where the acquisition question is ignored or treated as an afterthought, and acquisition studies which do not fully address how their results could be integrated into linguistic theory.
With this thesis, I hope to avoid this pitfall.
That is, I aim to develop a theoretical explanation of the resultative parameter that takes the acquisition question to be a crucial criterion for the success of my proposal; in other words, I assume that a grammatical theory of resultatives is adequate only if it answers the acquisition.
This statement is likely uncontroversial among generative syntactians, indeed it is perhaps an unstated criterion of all generative syntax.
I make it a stated criterion here as a way of ensuring that readers can hold me to it.

The answer I argue for is that a grammar generates resultatives only if it also generates adjectives without $\varphi$-features.
I argue that this 

\section{Theoretical Context}
The general theory that I assume here is a variety of what is called \textit{minimalist syntax} after Chomsky's (\citeyear{chomsky1995minimalist}) \textit{The Minimalist Program}.
Using the term \textit{minimalism} to refer to a theory of grammar, however, is perhaps incorrect, as minimalism is a metatheoretical position.
The contrast between theory and metatheory that I assume here is due to \textcite{chametzky1996theory}\footnote{
	Chametzky makes a three way distinction between metatheoretical, theoretical, and analytic work:
	\begin{quote}
		\textit{Metatheoretical} work is theory of theory, and divides into two sorts: general and (domain) specific.
		\textit{General} metatheoretical work is concerned with developing and investigating adequacy conditions for any theory in any domain.
		So, for example, it is generally agreed that theories should be (1) consisted and coherent, both internally and with other well-established theories; (2) explicit; and (3) simple. This sort of work is philosophical in nature \dots.
		\textit{Specific} metatheoretical work is concerned with adequacy conditions for theory in a particular domain.
		So, for example, in linguistics	we have Chomsky's (1964; 1965) familiar distinctions among observational, descriptive, and explanatory adequacy.
		Whether such work is ``philosophy'' or, in this case, ``linguistics'' seems to me a pointless question.
		
		\textit{Theoretical} work is concerned with developing and investigating primitives, derived concepts, and architecture within a particular domain of inquiry. 
		This work will also deploy and test concepts developed in metatheoretical work against the results of actual theory construction in a domain, allowing for both evaluation of the domain theory and sharpening of the metatheoretical concepts. 
		Note this well: deployment of metatheoretical concepts is \textit{not} metatheoretical work; it is theoretical work.
		
		\textit{Analytic} work is concerned with investigating the (phenomena of the) domain in question.
		It deploys and tests concepts and architecture developed in theoretical work, allowing for both understanding of the domain and sharpening of the theoretical concepts. 
		Note this well: deployment of theoretical concepts is \textit{not} theoretical work, it is analytic work. 
		Analytic work is what overwhelmingly most linguists do overwhelmingly most of the time.
		This is as it should, and indeed must, be: an empirical discipline only exists insofar as there is a community of scientists investigating the domain.
		For linguistics to be the science of language, this must be where linguists do their work.
		\parencite[xvii\textit{ff}]{chametzky1996theory}
	\end{quote}
	}
This distinction is evident when one considers the stark contrasts between the theories of grammar that are referred to as \textit{minimalist}.
For instance, \textcite{chomsky2000minimalist,hornstein2009theory,frampton2008crash,epstein2006derivations,borer2005name,borer2005normal,borer2013taking} all develop distinct minimialist theories of syntax.
They all, however, share a set of assumptions, likely due to their shared chomskyan heritage.
Since this thesis shares that heritage, it also shares those assumptions which I will list and explain below.

Most fundamentally, minimalist theories of grammar share a model of the language faculty called the \textit{Y Model} or the \textit{T Model}.
In this model, a narrowly syntactic ``module'' operates on items drawn from a lexicon to generate structures that are evaluated by a pair of modules:
the Sensorimotor (SM) module, commonly called the morphonology, or PF, which is responsible for external expression, and the Conceptual-Intentional (CI) module, commonly called the semantics, or LF, which is responsible for interpreting structures for use in internal system of thought.
\begin{figure}[h]
	\centering
	\caption{The Y Model of the language faculty}
	\label{fig:YModel}
\end{figure}
Beyond this, there is significant disagreement among minimalist theorists.

Another assumption common to minimalist syntacticians is the syntactic operation Merge.
The primary (and in some cases only) syntactic operation, Merge combines pairs of syntactic objects (\textit{i.e.}, lexical items or syntactic structures) to form larger syntactic objects.
The standard formulation of Merge is given in \cref{ex:MergeStd}\footnote{
	\textcite{hornstein2009theory} differs from the standard formulation, defining Merge as concatenation rather than set formation.
}.
\ex.\label{ex:MergeStd} Merge$(\alpha, \beta) = \left\{ \alpha, \beta \right\}$\\
iff both $\alpha$ and $\beta$ are syntactic objects.

Merge is responsible not only for creating new structures, but also for syntactic displacement.
To demonstrate this ability, \textcite{chomsky2004beyond} distinguishes between two cases of Merge: external and internal.
An instance of Merge$(\alpha, \beta)$ is external if neither $\alpha$, nor $\beta$ contains the other, and internal if $\alpha$ contains $\beta$ or vice versa.
Again, beyond the basics discussed above, there is little consensus among minimalist syntacticians.

While the Y Model and Merge seem to be the only instances of true consensus among minimalist syntacticians, there is growing accord about the underlying representation of certin types of word.
Specifically, many minimalist syntacticians now assume that a lexical word, like the noun \textit{chair}, minimally consists of an acategorial root and a categorizing head \parencite{borer2005name,marantz1997no}.
This is commonly expressed in the formalism of a vocabulary insertion rule from the theory of Distributed Morphology as in \cref{ex:VIRule}.
\ex.\label{ex:VIRule} \textit{chair} $\leftrightarrow \left\{ n, \sqrt{\textsc{chair}} \right\}$

There are competing views of the syntactic nature of morphological words, but as of this dissertation's writing this is the standard view, a view to which I subscribe, and therefore, I will not explicitly argue for it.

The theory I assume is not 100\% standard, though.
There are a number of assumptions that I make, which will certainly raise the eybrows of many if not most contemporary syntacticians.
I discuss these assumptions in \cref{sec:nonstandard}.

\subsection{Minimalism, biolinguistics and the SMT}
The minimalist program can be viewed as an effort to simplify GB theory without losing its empirical coverage.
That is, a minimalist analysis is one that compares two hypotheses that have roughly equivalent empirical power, and chooses the simpler one.
However, as \textcite{chomsky1965aspects} discusses, there is no such thing as an absolute measure of simplicity.
Consider, for instance, the following equivalent expressions of arithmetic using the more standard infix notation in \cref{ex:StdAddition} and lambda calculus in \cref{ex:ChurchAddition}.
\ex.\label{ex:StdAddition} $3 + 2$

\ex.\label{ex:ChurchAddition} $\lambda f \lambda x . ((\lambda f \lambda x . f(f(f x))) f(\lambda f \lambda x . (f(f x))(f x)))$

While it may seem obvious that \cref{ex:StdAddition} which constists of a mere three symbols is simpler than \cref{ex:ChurchAddition} with its 41 characters, it becomes less obvious when we compare as wholes, the systems that they are drawn from.
Performing arithmetic with infix notation requires rote memorization of the results of single digit addition, multiplication, subraction, and division and rather complex algorithms for larger numbers (\textit{e.g.}, long division).
The lambda calculus, on the other hand, uses two very simple operations, requiring no rote memorization for their application.
From this standpoint the lambda calculus is vastly simpler.
The point here is that a judgement of simplicity depends on the choice of simplicity metric.

This is not to say that the choice of simplicity metric is arbitrary.
On the contrary, since any choice of simplicity metric will be a major factor in the deciding between theories, it must be justified.
The main simplicity metric of the minimalist program is the Strong Minimalist Thesis (SMT) which states that the language faculty is an optimal solution to interface conditions \parencite{chomsky2001derivation}.
The justification for SMT, which is often repeated by Chomsky, comes from evolutionary biology.
It begins with two observations, the results of several decades of linguistics research.
The first observation is that the human language faculty is unique in the biological world, that nothing does language like we do, to use Norbert Hornstein's formulation.
The second observation is that the language faculty is uniform across our species, that a child born in a remote African village, but raised in Dublin would acquire an Irish variety of English with the same ease as a child born and raised in Dublin.
these observations suggest that the language faculty emerged quite suddenly, likely due to a single genetic mutation in a single individual.
It follows from this that whatever portion of our cognitive system that is specific to language must be incredibly simple.

The SMT provides the following priniciples for minimalist syntactic analysis and theorizing:
(1) Assume the simplest possible recursive syntax (\textit{i.e.}, one that consists only of simplest Merge).
(2) Assume that no other module of the language faculty is capable of recursion.
(3) When you encounter a proposed property of the language faculty or principle of linguistic theory either 
	(a) show that it can be reduced to Merge,
	(b) show that it can be reduced to interface conditions,
	(c) show that it can be reduced to independent principles, or
	(d) show that it can be reduced to a combination of Merge, interface conditions, and independent principles.

\end{document}                                                                                                            
